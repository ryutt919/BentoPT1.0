import cv2 as cv
import numpy as np
import torch
from ultralytics import YOLO
import os
from collections import deque
from mmengine.config import Config
from mmaction.apis import init_recognizer
from typing import Tuple, List, Optional, Dict
from mmengine.dataset import Compose  
from mmaction.datasets.transforms.formatting import FormatGCNInput, PackActionInputs  


class PoseEstimator:
    def __init__(self):
        # YOLO ëª¨ë¸ ë¡œë“œ
        self.pose_model = YOLO('yolov8x-pose.pt')
        self.pose_model.verbose = False
        
        # ST-GCN ëª¨ë¸ ë¡œë“œ
        config_path = "configs/custom_config.py"
        checkpoint_path = "models/lunge/best_acc_top1_epoch_50.pth"
        self.stgcn_context = self._load_stgcn_model(
            config_path, checkpoint_path, topk=3, device="cuda:0"
        )
        
        # COCO í¬ë§·ì˜ 17ê°œ í‚¤í¬ì¸íŠ¸ ì´ë¦„ ì •ì˜
        self.keypoint_names = [
            'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
            'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
            'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
            'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
        ]
        
        # ëŸ°ì§€ ë™ì‘ í´ë˜ìŠ¤ ë§¤í•‘
        self.class_names = {
            -1: "ë¶„ì„ ì¤‘...",
            0: "íŒë³„ ë¶ˆê°€",
            1: "ì˜¬ë°”ë¥¸ ìì„¸",
            2: "ë¬´ë¦ì´ ë°œëì„ ë„˜ì–´ê°",
            3: "ë“±ì´ êµ¬ë¶€ëŸ¬ì§",
            4: "ë°œì´ ë¶ˆì•ˆì •í•¨",
            5: "ëª¸í†µì´ í”ë“¤ë¦¼",
            6: "ë’·ë¬´ë¦ì´ ë°”ë‹¥ì— ë‹¿ìŒ",
            7: "ë¬´ê²Œì¤‘ì‹¬ì´ ë’¤ë¡œ ì ë¦¼",
            8: "ìµœëŒ€ ìˆ˜ì¶• í•„ìš”",
            9: "ìµœëŒ€ ì´ì™„ í•„ìš”"
        }
        
        # í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬
        self.feedback_list = []
        self.feedback_history = deque(maxlen=5)  # ìµœê·¼ 5ê°œì˜ í”¼ë“œë°± ê¸°ì–µ
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° íŒŒë¼ë¯¸í„°
        self.window_size = 32
        self.stride = 16
        self.buffer_size = 64
        self.keypoints_buffer = deque(maxlen=self.buffer_size)
        self.frame_numbers_buffer = deque(maxlen=self.buffer_size)
        self.frame_counter = 0
        
        self.pipeline = Compose([
            FormatGCNInput(num_person=1),
            PackActionInputs()
        ])

    def _load_stgcn_model(self, config_path: str,
                         checkpoint_path: str,
                         device: str = "cuda:0",
                         topk: int = 5) -> Dict:
        cfg   = Config.fromfile(config_path)
        model = init_recognizer(cfg, checkpoint_path, device=device)
        model.eval()
        return {"model": model, "device": device, "topk": topk}        
        
    def extract_keypoints(self, frame: np.ndarray, 
                         frame_number: int) -> Optional[np.ndarray]:
        """í•œ í”„ë ˆì„ì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ"""
        results = self.pose_model(frame, conf=0.3, verbose=False)[0]  # ë‚®ì€ confidenceë„ í—ˆìš©
        
        if results.keypoints is None:
            return None
            
        kpts = results.keypoints.data.cpu().numpy()
        if len(kpts) == 0:
            return None
            
        keypoints = kpts[0]  # ì²« ë²ˆì§¸ ì‚¬ëŒë§Œ
        
        # ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬
        if len(keypoints) != 17:
            return None
            
        # ì¤‘ì•™ê°’ í•„í„°ë¡œ ë…¸ì´ì¦ˆ ê°ì†Œ
        coords = keypoints[:, :2]  # (V, 2)
        conf = keypoints[:, 2:]    # (V, 1)
        
        # ì‹œê°„ì¶•ìœ¼ë¡œ ì¤‘ì•™ê°’ í•„í„°ë§ ìˆ˜í–‰
        if len(self.keypoints_buffer) > 0:
            prev_coords = np.array(self.keypoints_buffer)[-1, :, :2]
            coords = (coords + prev_coords) / 2  # ì´ì „ í”„ë ˆì„ê³¼ í‰ê· 
            
        # í•„í„°ë§ëœ ì¢Œí‘œì™€ confidence ì¬ê²°í•©
        keypoints = np.concatenate([coords, conf], axis=1)
            
        return keypoints
        
    def process_frame(self, frame: np.ndarray, frame_number: int) -> Optional[Dict]:
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ë¶„ì„ ìˆ˜í–‰"""
        keypoints = self.extract_keypoints(frame, frame_number)
        
        if keypoints is not None:
            self.keypoints_buffer.append(keypoints)
            self.frame_numbers_buffer.append(frame_number)
            
            # ì¶©ë¶„í•œ í”„ë ˆì„ì´ ìŒ“ì´ë©´ ë¶„ì„ ìˆ˜í–‰
            if len(self.keypoints_buffer) >= self.window_size:
                result = self.analyze_pose()
                if result is not None:
                    self.update_feedback_list(result)
                return result
            
        return None
        
    def analyze_pose(self) -> Optional[Dict]:
        """ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í˜„ì¬ í¬ì¦ˆ ì‹œí€€ìŠ¤ ë¶„ì„ (íŒŒì´í”„ë¼ì¸ + permute ì ìš©)"""
        # 1) ì¶©ë¶„í•œ ë²„í¼ í™•ì¸
        if len(self.keypoints_buffer) < self.window_size:
            print(f"[DEBUG] Buffer not full: {len(self.keypoints_buffer)}/{self.window_size}")
            return None

        # 2) ì‹œí€€ìŠ¤ ë°°ì—´í™”
        seq      = list(self.keypoints_buffer)[-self.window_size:]
        sequence = np.array(seq, dtype=np.float32)       # (T, V, 3)
        print(f"[DEBUG] Raw sequence shape: {sequence.shape}")

        # 3) coords & confidence ë¶„ë¦¬
        coords = sequence[:, :, :2]                      # (T, V, 2)
        conf   = sequence[:, :, 2:]                      # (T, V, 1)
        score3d = conf[..., 0]                           # (T, V)

        # 4) íŒŒì´í”„ë¼ì¸ ì…ë ¥ dict êµ¬ì„±
        data = {
            'keypoint': coords[np.newaxis, ...],   # (1, T, V, 2)
            'keypoint_score': score3d[np.newaxis, ...],  # (1, T, V)
            'num_person': 1
        }
        print(f"[DEBUG] Before pipeline: keypoint {data['keypoint'].shape}, score {data['keypoint_score'].shape}")

        # 5) FormatGCNInput â†’ PackActionInputs ì ìš©
        packed = self.pipeline(data)
        x = packed['inputs']  # (N, M, T, V, C)
        
        # 6) GPUë¡œ ì´ë™
        x = x.to(self.stgcn_context["device"])
        print(f"[DEBUG] After pipeline and device move: inputs.shape : {x.shape}, device: {x.device}")

        try:
            print("[DEBUG] Starting model inference...")
            with torch.no_grad():
                # backboneì— ì§ì ‘ ì „ë‹¬
                feats = self.stgcn_context["model"].backbone(x)
                out = self.stgcn_context["model"].cls_head(feats)
    
            # 8) ê²°ê³¼ ì²˜ë¦¬
            prob         = torch.softmax(out[0], dim=-1)
            scores_k, labels_k = torch.topk(prob, k=self.stgcn_context["topk"])
            print("\n[DEBUG] Predictions:")
            for idx, (score, label) in enumerate(zip(scores_k.cpu().numpy(),
                                                     labels_k.cpu().numpy()), 1):
                print(f" {idx}. Class {label}: {score:.3f}")

            return {
                "scores": scores_k.cpu().numpy(),
                "labels": labels_k.cpu().numpy(),
                "feedback": self.feedback_list
            }

        except Exception as e:
            print(f"\n[ERROR] Pipeline failed: {e.__class__.__name__}")
            import traceback; traceback.print_exc()
            if 'x' in locals():
                print("\nFinal tensor state:")
                print(f" - Shape : {x.shape}")
                print(f" - Dtype : {x.dtype}")
                print(f" - Device: {x.device}")
            return None

        
    def update_feedback_list(self, result: Dict):
        """í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        scores = result["scores"]
        labels = result["labels"]
        
        # í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        self.feedback_list = []
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ í”¼ë“œë°± í•„í„°ë§
        high_conf_feedbacks = []
        low_conf_feedbacks = []
        
        for label, score in zip(labels, scores):
            label = int(label)
            if label == 1:  # ì˜¬ë°”ë¥¸ ìì„¸
                if score >= 0.7:  # ë†’ì€ ì‹ ë¢°ë„ë¡œ ì˜¬ë°”ë¥¸ ìì„¸ ê°ì§€
                    feedback = {
                        "label": label,
                        "message": "ì •í™•í•œ ëŸ°ì§€ ìì„¸ì…ë‹ˆë‹¤ğŸ‘",
                        "confidence": float(score),
                        "priority": 1
                    }
                    high_conf_feedbacks.append(feedback)
                continue
                
            # ì˜ëª»ëœ ìì„¸ì— ëŒ€í•œ í”¼ë“œë°±
            if score >= 0.5:  # ë†’ì€ ì‹ ë¢°ë„
                feedback = {
                    "label": label,
                    "message": self.class_names[label],
                    "confidence": float(score),
                    "priority": 2
                }
                high_conf_feedbacks.append(feedback)
            elif score >= 0.3:  # ë‚®ì€ ì‹ ë¢°ë„
                feedback = {
                    "label": label,
                    "message": self.class_names[label],
                    "confidence": float(score),
                    "priority": 3
                }
                low_conf_feedbacks.append(feedback)
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í”¼ë“œë°± ì •ë ¬ ë° ë³‘í•©
        self.feedback_list = sorted(high_conf_feedbacks + low_conf_feedbacks, 
                                  key=lambda x: (x["priority"], -x["confidence"]))
        
        # í”¼ë“œë°± ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 3ê°œ)
        self.feedback_list = self.feedback_list[:3]
        
        # í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        if self.feedback_list:
            self.feedback_history.append(self.feedback_list)
        
    def get_feedback_history(self) -> List[List[Dict]]:
        """ìµœê·¼ í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return list(self.feedback_history)
        
    def clear_buffer(self):
        """ë²„í¼ ì´ˆê¸°í™”"""
        self.keypoints_buffer.clear()
        self.frame_numbers_buffer.clear()
        self.frame_counter = 0
        self.feedback_list = []
        self.feedback_history.clear()
        
    def get_buffer_size(self):
        """í˜„ì¬ ë²„í¼ í¬ê¸° ë°˜í™˜"""
        return len(self.keypoints_buffer)
